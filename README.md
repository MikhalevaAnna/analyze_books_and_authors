# Провести анализ данных по авторам и книгам с пмощью PySpark

Есть два набора данных: информация о книгах и информация об авторах. <br>
Нужно объединить эти данные и провести анализ, чтобы найти различные статистики о книгах и авторах.

## Данные
### Таблица `books`:

`book_id`: ID книги <br>
`title`: Название книги <br>
`author_id`: ID автора <br>
`genre`: Жанр книги <br>
`price`: Цена книги <br>
`publish_date`: Дата публикации (в формате YYYY-MM-DD) <br>

### Таблица authors:

`author_id`: ID автора <br>
`name`: Имя автора <br>
`birth_date`: Дата рождения автора (в формате YYYY-MM-DD) <br>
`country`: Страна автора <br>

## Выполняем следующие пункты по порядку:

### 1.Чтение данных:

Загружаем данные из **CSV** файлов в **DataFrame**. <br>
**CSV** файл `books` можно скачать по ссылке - [https://disk.yandex.ru/d/7ObST0hRb5E4qA](https://disk.yandex.ru/d/uAFqLYZR41-z9Q) , 
а `authors` по ссылке - [https://disk.yandex.ru/d/q4K_cpm1rAamhA](https://disk.yandex.ru/d/q4K_cpm1rAamhA)

### 2. Обработка данных:

Преобразуем столбцы **publish_date** и **birth_date** в формат даты. 
### 3. Объединение данных:

Объединим таблицы `books` и `authors` по **author_id**.
### 4. Анализ данных:

4.1 Найдем топ-5 авторов, книги которых принесли наибольшую выручку. <br>
4.2 Найдем количество книг в каждом жанре. <br>
4.3 Подсчитаем среднюю цену книг по каждому автору. <br>
4.4 Найдем книги, опубликованные после 2000 года, и отсортируйте их по цене. <br>

### 5. Результаты:

## Выведим результаты анализа в виде таблиц:
Результат 4.1
